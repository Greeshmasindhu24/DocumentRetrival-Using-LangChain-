{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oYhuag-f_RZcfRBTAnrswftFFhBIVccC",
      "authorship_tag": "ABX9TyMZh+vKgQOz4yoKnI2u/kYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Greeshmasindhu24/DocumentRetrival-Using-LangChain-/blob/main/7_Document_Query_Retrieval_and_Vector_Database_using_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import fitz\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NumpyEncoder, self).default(obj)\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                text += page.get_text(\"text\") + \"\\n\"\n",
        "    except Exception as e:\n",
        "        print(\"Error with PyMuPDF, trying pdfplumber:\", e)\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
        "        except Exception as e:\n",
        "            print(\"Error extracting text from PDF:\", e)\n",
        "    return text\n",
        "\n",
        "def store_in_vector_db(text):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    texts = text_splitter.split_text(text)\n",
        "\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "    vector_store = FAISS.from_texts(texts, embedding_model)\n",
        "    vector_store.save_local(\"faiss_index\")\n",
        "    print(\"Vector database saved!\")\n",
        "    return vector_store\n",
        "\n",
        "def query_vector_db(query, k=1):\n",
        "    try:\n",
        "        embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        vector_store = FAISS.load_local(\n",
        "            \"faiss_index\",\n",
        "            embedding_model,\n",
        "            allow_dangerous_deserialization=True\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            results = vector_store.similarity_search_with_score(query, k=1)\n",
        "            formatted_results = []\n",
        "            for doc, score in results:\n",
        "                if hasattr(score, 'item'):\n",
        "                    score = score.item()\n",
        "                similarity = 1 / (1 + score)\n",
        "\n",
        "                formatted_results.append({\n",
        "                    \"content\": doc.page_content,\n",
        "                    \"metadata\": doc.metadata,\n",
        "                    \"similarity_score\": float(similarity)\n",
        "                })\n",
        "        except (AttributeError, TypeError) as e:\n",
        "            print(f\"Using standard similarity search: {e}\")\n",
        "            results = vector_store.similarity_search(query, k=1)\n",
        "            formatted_results = []\n",
        "            for i, doc in enumerate(results):\n",
        "                similarity = 0.1 - (i * 0.1)\n",
        "                formatted_results.append({\n",
        "                    \"content\": doc.page_content,\n",
        "                    \"metadata\": doc.metadata,\n",
        "                    \"similarity_score\": float(similarity)\n",
        "                })\n",
        "        formatted_results.sort(key=lambda x: x[\"similarity_score\"], reverse=True)\n",
        "        return json.dumps(formatted_results, indent=2, cls=NumpyEncoder)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying vector database: {e}\")\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "def main():\n",
        "    pdf_path = \"/content/drive/MyDrive/Hands on/power-bi-question.pdf\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(\"File not found!\")\n",
        "        return\n",
        "\n",
        "    print(\"Extracting text from PDF...\")\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    if text:\n",
        "        print(\"Text extracted successfully!\")\n",
        "        print(\"Storing in vector database...\")\n",
        "        store_in_vector_db(text)\n",
        "        query = \"what is power bi?\"\n",
        "        print(\"Querying: \", query)\n",
        "        results_json = query_vector_db(query)\n",
        "        print(results_json)\n",
        "    else:\n",
        "        print(\"Failed to extract text.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV5-LJIcBmYk",
        "outputId": "5d04a8cb-3d53-4340-e7b0-cc708c3891a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from PDF...\n",
            "Text extracted successfully!\n",
            "Storing in vector database...\n",
            "Vector database saved!\n",
            "Querying:  what is power bi?\n",
            "[\n",
            "  {\n",
            "    \"content\": \"addressed in Power BI?\\nMany-to-many relationships comprise a bridge table showing the combinations of two\\ndimensions. These combinations can either be possible or those that have occurred.\\n\\u25cf\\nBi-directional cross-filtering relationships can be used in PBIX.\\n\\u25cf\\nDAX is used per metric to check or modify filter context.\\n\\u25cf\\nCROSSFILTER is used in Power Pivot in Excel.\\n46. What is the difference between a Power BI Dataset, a Report,\\nand a Dashboard?\\nPower BI Dataset\\nReport\\nDashboard\\nThe\\nsource\\nto\",\n",
            "    \"metadata\": {},\n",
            "    \"similarity_score\": 0.1147263867319606\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}